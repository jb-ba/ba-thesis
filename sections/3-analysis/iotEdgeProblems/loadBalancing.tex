\subsubsection{Load Balancing}
Load balancing in a distributed environment is difficult as the ingress node needs a complete network topology at any given moment in time. This is one of the reasons why Kubernetes refreshes its node status so often. If a external request comes in at the master it needs to know where to forward the traffic. In the previous section \cref{sec:singleVsMultiCluster} \nameref{sec:singleVsMultiCluster} I discussed the advantages and disadvantages of multi-cluster in contrast to single clusters and load balancing is a perfect example why the decision has to be carefully weight. A full Kubernetes cluster on the edge comes with the advantage of having a full control plane on the edge and, thus, being able to do load balacing on the edge, with for example Istio Ingress Gateay. If the master nodes taint were to be removed it could even become part of the operational unit of the cluster.\\
But having a cluster at edge comes with its downside. It needs a lot more management than a single cluster setup. It consumes drastically more resources than having only worker nodes and it needs a stable connection between the cluster nodes to work. But if resource consumption on the master is not an issue Kubernetes coupled with a load balancer provide more features and safeguarding than most other load balancers do. Kubernetes always ensures that pods inside the cluster are healthy and reachable and if a pod goes down, Kubernetes will automatically spawn a new one. The internal load balancer can use this information and always route to an available pod. Other gateways like, Kong API Gateway, can not do this. Also with Istio it becomes possible to do very fine grained traffic routing, somthing I will discuss in the next section \cref{} \nameref{}.\\
Finally, internal load balancing\footnote{Load balancing withing one node.} is possible through normal API gateways and the deployment of multiple pods listening on different ports. For example, one NGINX container could function as load balancer for 5 docker containers in the background. In Kubernetes this could be solved with affinities. As soon as a node runs certain pods, a load balancer could be automotically side loaded.