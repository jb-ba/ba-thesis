% \subsubsection{Deployment Strategies}
\comment{
deployment vs statefulset vs daemonset
clusterIP vs nodeport
Taints, nodeselector, affinities pod/node
namespaces
}
Kubernetes provides many API resources and the most important once for application deployments are discussed here.
The \textit{service} resource provides an abstraction between the network interface and the actual application. From an outsiders view, it is possible to call the Kubernetes ingress under an address subsection\footnote{E.g. In \url{https://example.com/hello} the path \textit{/hello} is the subsection} and get to a pod running somewhere inside the cluster without knowing its specific address. From the inside it enables routing between services based on the service name. Creating services is the usual deployment strategy for applications.

The service also defines how its pods are accessible. By default, pods are assigned a \textit{clusterIP} making it only accessible from inside the cluster. Outside requests have to go through the Kubernetes ingress and are then routed to a pod. This makes little sense on the edge, where latency is key and an Internet connection is not guaranteed. Instead, it is possible to define a \textit{nodePort} inside a service on a Kubernetes predefined port range. This port is then exposed by the host machine so that outside traffic can directly connect to the pod.

Kubernetes also offers different resources for core workloads, \textit{Deployments},  \textit{StatefulSets},  \textit{DaemonSets} and  \textit{ReplicationController}, which should not be used anymore\cite{CoreWorkloadKubernetes66:online}. These resources directly define what is running inside a pod. As with all Kubernetes API resources, they describe a desired state and the Kubernetes control plane works towards fulfilling this desired state. Deployments are mainly used for stateless services. StatefulSets are used for stateful services and DaemonSets deploy pods on each node. For the edge all workloads are important, but it is important to choose the correct workload for a desired result. Inside the workloads specifications it is also possible to define resources. Because of the resource limitations of edge devices auto-scaling is not possible and devices can get quickly overwhelmed by too many tasks. This also puts an emphasis on the prioritization of workloads. In case the hosts computing resources are not enough some workloads have to prioritized over others. 

Kubernetes offers powerful concepts to achieve the correct scheduling of pods on desired nodes. They are \textit{NodeSelector}, \textit{taints}, \textit{tolerations}, \textit{affinities} and \textit{anti-affinities}. A NodeSelector specifies which tags have to be present on a node for a pod to be scheduled on. Taints are added to nodes and specify that only pods with the matching toleration can run on the node. E.g. the master has the taint \textit{NoSchedule} which means, only pods with the matching toleration can be scheduled on a the master. Finally, affinities and anti-affinities, offer a way for pods to be scheduled (or not) on either pods or nodes with a specific tag. This gives operators the ability to add workloads only on nodes which are already running another pod, or with anit-affinity, where a pod is not present. These are very powerful administrative tools and need to be selected carefully.

Finally, \textit{namespaces} offer the ability to separate one physical cluster into mulitple virtual clusters. Most Kubernetes resources are saved inside namespaces which are especially important in a single-cluster setup with multiple user groups. Administrators can define namespaces and assign them resource limits as well as nodes via the \textit{PodNodeSelector}. This makes it possible to assign each logical edge deployment a virtual cluster and developers can only modify resources within that namespace or virtual cluster. It is also possible to define role-based access control (RBAC) to limit what a specific user or user group can modify inside a namespace. 
